{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Cuda is Availabe\n",
      "Using cuda:4 device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda is Availabe\")\n",
    "else:\n",
    "    print(\"Cuda Can't be found\")\n",
    "\n",
    "# Just the device selection options\n",
    "device = (\n",
    "    \"cuda:4\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2)\n",
    "        self.act1 = nn.Tanh()\n",
    "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0)\n",
    "        self.act2 = nn.Tanh()\n",
    "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16, 120, kernel_size=5, stride=1, padding=0)\n",
    "        self.act3 = nn.Tanh()\n",
    "\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(1*1*120, 84)\n",
    "        self.act4 = nn.Tanh()\n",
    "        self.fc2 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input 1x28x28, output 6x28x28\n",
    "        x = self.act1(self.conv1(x))\n",
    "        # input 6x28x28, output 6x14x14\n",
    "        x = self.pool1(x)\n",
    "        # input 6x14x14, output 16x10x10\n",
    "        x = self.act2(self.conv2(x))\n",
    "        # input 16x10x10, output 16x5x5\n",
    "        x = self.pool2(x)\n",
    "        # input 16x5x5, output 120x1x1\n",
    "        x = self.act3(self.conv3(x))\n",
    "        # input 120x1x1, output 84\n",
    "        x = self.act4(self.fc1(self.flat(x)))\n",
    "        # input 84, output 10\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import json\n",
    "class ImageNetKaggle(Dataset):\n",
    "    def __init__(self, root, split, transform=None):\n",
    "        self.samples = []\n",
    "        self.targets = []\n",
    "        self.transform = transform\n",
    "        self.syn_to_class = {}\n",
    "        with open(os.path.join(root, \"imagenet_class_index.json\"), \"rb\") as f:\n",
    "                    json_file = json.load(f)\n",
    "                    for class_id, v in json_file.items():\n",
    "                        self.syn_to_class[v[0]] = int(class_id)\n",
    "        with open(os.path.join(root, \"ILSVRC2012_val_labels.json\"), \"rb\") as f:\n",
    "                    self.val_to_syn = json.load(f)\n",
    "        samples_dir = os.path.join(root, \"\", split)\n",
    "        for entry in os.listdir(samples_dir):\n",
    "            \n",
    "            syn_id = self.val_to_syn[entry]\n",
    "            target = self.syn_to_class[syn_id]\n",
    "            sample_path = os.path.join(samples_dir, entry)\n",
    "            self.samples.append(sample_path)\n",
    "            self.targets.append(target)\n",
    "    def __len__(self):\n",
    "            return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "            x = Image.open(self.samples[idx]).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                x = self.transform(x)\n",
    "            return x, self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 5193941.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 17382076.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:01<00:00, 1391021.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 9824924.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0,), (128,)),\n",
    "])\n",
    "train = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test = torchvision.datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(train, shuffle=True, batch_size=100)\n",
    "testloader = torch.utils.data.DataLoader(test, shuffle=True, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "optimizer = None\n",
    "loss_fn = None\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "def load_model(model_name):\n",
    "    global model\n",
    "    if model_name.lower() == 'resnet':\n",
    "        model = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
    "    elif model_name.lower() == 'alexnet':\n",
    "        model =torchvision.models.alexnet(weights=\"DEFAULT\")\n",
    "    elif model_name.lower() =='googlenet':\n",
    "        model=torchvision.models.googlenet(weights=\"DEFAULT\")\n",
    "    elif model_name.lower() =='vgg16':\n",
    "        model = torchvision.models.vgg16(weights=\"DEFAULT\")\n",
    "    elif model_name.lower() =='lenet':\n",
    "        global  optimizer, loss_fn\n",
    "        print (os.path.curdir)\n",
    "        model = LeNet5().to(device)\n",
    "        optimizer = optim.Adam(model.parameters())\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "        MODEL_FILENAME=os.path.join(BASE_DIR, 'model.sav')\n",
    "        if (os.path.isfile(MODEL_FILENAME) != True):\n",
    "            __train__(model, 10)\n",
    "            torch.save(model.state_dict(),MODEL_FILENAME)\n",
    "            print (f'Model saved to {MODEL_FILENAME}')\n",
    "        else:\n",
    "            model.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "    model.to(device)\n",
    "    model.eval()   \n",
    "\n",
    "\n",
    "imagenet_path = os.path.join(BASE_DIR, 'imagenet')\n",
    "\n",
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "val_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "dataset = ImageNetKaggle(imagenet_path, \"val\", val_transform)\n",
    "dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=64, # may need to reduce this depending on your GPU \n",
    "            num_workers=8, # may need to reduce this depending on your num of CPUs and RAM\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            pin_memory=True\n",
    "        )\n",
    "def __test__ (model__,model_name)-> float:\n",
    "    if model_name.lower() =='lenet':\n",
    "        model__.eval()\n",
    "        acc = 0\n",
    "        count = 0\n",
    "        for X_batch, y_batch in testloader:\n",
    "            X_batch = X_batch.to(device); y_batch = y_batch.to(device)\n",
    "            y_pred = model__(X_batch)\n",
    "            acc += (torch.argmax(y_pred, 1) == y_batch).float().sum()\n",
    "            count += len(y_batch)\n",
    "        acc = acc / count\n",
    "        acc__ = acc.cpu()\n",
    "        return acc__.numpy()*100\n",
    "    else:\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in tqdm(dataloader):\n",
    "                x= x.to(device)\n",
    "                y=y.to(device)\n",
    "                y_pred = model(x)\n",
    "                acc += (torch.argmax(y_pred, 1) == y).float().sum()\n",
    "                total += len(y)\n",
    "        acc=acc / total\n",
    "        acc__=acc.cpu()\n",
    "        return acc__.numpy()*100\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import datetime, time,threading, psutil\n",
    "\n",
    "class SystemStatsGatherer:\n",
    "    def __init__(self,  interval=2):\n",
    "        self.temp_dict = {}\n",
    "        self.not_firstime = False\n",
    "        self.diskio_fieldname = ['read_count', 'write_count','read_bytes', 'write_bytes', 'read_time', 'write_time', 'read_merged_count', 'write_merged_count', 'busy_time']\n",
    "        self.diskio_fieldvals = [0.0 , 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0 , 0.0, 0.0]\n",
    "        self.swap_mem_fieldname = ['total', 'used', 'free', 'percent', 'sin', 'sout']\n",
    "        self.swap_mem_fieldvals = [0.0 , 0.0, 0.0, 0.0 , 0.0, 0.0]\n",
    "        self.virtual_mem_fieldname = ['total', 'available','percent', 'used', 'free', 'active', 'inactive', 'buffers', 'cached', 'shared', 'slab']\n",
    "        self.virtual_mem_fieldvals = [0.0 , 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0 , 0.0, 0.0, 0.0, 0.0]\n",
    "        self.tempsensor_fieldname = ['current','high', 'critical']\n",
    "        self.tempsensor_fieldvals = [0.0 , 0.0, 0.0]\n",
    "        self.samplerThread = threading.Thread(target=self.samplerThread)\n",
    "        self.samplingInterval = interval\n",
    "        self.stopThread = False\n",
    "\n",
    "\n",
    "    def SampleTemp(self):\n",
    "\n",
    "        tempsensor_name = \"\"\n",
    "        # res_temp = psutil.sensors_temperatures()\n",
    "        res_diskio = psutil.disk_io_counters(perdisk=False, nowrap=True)\n",
    "        res_swapmem = psutil.swap_memory()\n",
    "        res_virtmem = psutil.virtual_memory()\n",
    "        ctr = 0\n",
    "        global not_firstime\n",
    "        ts = datetime.datetime.now()\n",
    "        if (self.not_firstime == False):\n",
    "            self.temp_dict['time'] = [str(ts)]\n",
    "        else:\n",
    "            self.temp_dict['time'] += [str(ts)]\n",
    "\n",
    "        ## get CPU Load averages\n",
    "        loadavgs = [x / psutil.cpu_count() * 100 for x in psutil.getloadavg()]\n",
    "        if (self.not_firstime == False):\n",
    "            self.temp_dict['cpuloadavg_1min'] = loadavgs[0]\n",
    "            self.temp_dict['cpuloadavg_5min'] = loadavgs[1]\n",
    "            self.temp_dict['cpuloadavg_15min'] = loadavgs[2]\n",
    "        else:\n",
    "            self.temp_dict['cpuloadavg_1min'] += loadavgs[0]\n",
    "            self.temp_dict['cpuloadavg_5min'] += loadavgs[1]\n",
    "            self.temp_dict['cpuloadavg_15min'] += loadavgs[2]\n",
    "\n",
    "\n",
    "        ## Process the Virtual Memory readings\n",
    "        ctr = 0\n",
    "        for val in res_virtmem:\n",
    "            if (self.not_firstime == False):\n",
    "                self.temp_dict['vm_'+self.virtual_mem_fieldname[ctr]] = [val]\n",
    "            else:\n",
    "                self.temp_dict['vm_'+self.virtual_mem_fieldname[ctr]] += [val]\n",
    "            ctr += 1\n",
    "        ## Process the Swap Memory readings\n",
    "        ctr = 0\n",
    "        for val in res_swapmem:\n",
    "            if (self.not_firstime == False):\n",
    "                self.temp_dict['swap_'+self.swap_mem_fieldname[ctr]] = [val]\n",
    "            else:\n",
    "                self.temp_dict['swap_'+self.swap_mem_fieldname[ctr]] += [val]\n",
    "            ctr += 1\n",
    "        ## Process the DiskIO readings\n",
    "        ctr = 0\n",
    "        for val in res_diskio:\n",
    "            if (self.not_firstime == False):\n",
    "                self.temp_dict['diskio_'+self.diskio_fieldname[ctr]] = [val]\n",
    "            else:\n",
    "                self.temp_dict['diskio_'+self.diskio_fieldname[ctr]] += [val]\n",
    "            ctr += 1\n",
    "        ## Process the Temperature readings\n",
    "        # for key,values in res_temp.items():\n",
    "        #     # print (key,' => ',values)\n",
    "        #     for temp_elems in values:\n",
    "        #         # print (temp_elems)\n",
    "        #         tempsensor_name = key\n",
    "        #         ctr = 0;title_field = True\n",
    "        #         for val in temp_elems:\n",
    "        #             if (title_field == True):\n",
    "        #                 tempsensor_name +=  '-'+str(val)\n",
    "        #                 title_field = False\n",
    "        #             else:\n",
    "        #                 self.tempsensor_fieldvals[ctr] = val\n",
    "        #                 ctr += 1\n",
    "                        \n",
    "                    # print(key,'-', '=>',tempsensor_fieldname[ctr],'-->',sensor_val)\n",
    "                # print (tempsensor_name,'=>',tempsensor_fieldvals)\n",
    "                # ctr = 0\n",
    "                # for elems in self.tempsensor_fieldvals:\n",
    "                #     # print (tempsensor_name+'-'+tempsensor_fieldname[ctr],'=>',elems)\n",
    "                #     if (self.not_firstime == False):\n",
    "                #         self.temp_dict[tempsensor_name+'-'+self.tempsensor_fieldname[ctr]] = [elems]\n",
    "                #     else:\n",
    "                #         self.temp_dict[tempsensor_name+'-'+self.tempsensor_fieldname[ctr]] += [elems]\n",
    "                #     ctr += 1\n",
    "        self.not_firstime = True\n",
    "\n",
    "    def getReadings(self):\n",
    "        return self.temp_dict\n",
    "    \n",
    "    def samplerThread(self):\n",
    "        while (self.stopThread != True):\n",
    "            self.SampleTemp()\n",
    "            time.sleep(self.samplingInterval)\n",
    "        return\n",
    "    \n",
    "    def startSampling(self):\n",
    "        self.stopThread = False\n",
    "        self.samplerThread.start()\n",
    "        return \n",
    "\n",
    "    def stopSampling(self):\n",
    "        self.stopThread = True\n",
    "        self.samplerThread.join()\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:126: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:126: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_2978743/3245841989.py:126: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(io.StringIO(prof_result_back), sep=\"\\s\\s+\")\n",
      "STAGE:2024-04-09 20:35:17 2978743:2978743 ActivityProfilerController.cpp:314] Completed Stage: Warm Up"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning method: l1_unstructured\n",
      "0.0\n",
      "Profiling run completed.\n",
      "Compiling result table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 64/782 [00:16<02:59,  4.00it/s]\n",
      "/tmp/ipykernel_2978743/3245841989.py:126: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(io.StringIO(prof_result_back), sep=\"\\s\\s+\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfiling run completed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompiling result table\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    110\u001b[0m prof\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m--> 111\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43m__test__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m prof\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfiling run completed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCompiling result table\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 83\u001b[0m, in \u001b[0;36m__test__\u001b[0;34m(model__, model_name)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[0;32m---> 83\u001b[0m         x\u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m         y\u001b[38;5;241m=\u001b[39my\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     85\u001b[0m         y_pred \u001b[38;5;241m=\u001b[39m model(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "\n",
    "# COLUMN_NAMES = ['prune-config', 'prune-ratio','vm-percent','swap-percent','cpuloadavg-1min', 'cpuloadavg-5min', 'ratio','memory_consumption','acc']\n",
    "df_final = pd.DataFrame()\n",
    "model_name = input(\"Enter the model name: \")\n",
    "\n",
    "load_model(model_name)\n",
    "\n",
    "pruning_method = input(\"Enter the pruning method: \")\n",
    "\n",
    "# Define a list of supported pruning techniques\n",
    "supported_pruning_methods = ['l1_unstructured', 'random_unstructured','ln_structured','random_structured']  # Add more pruning methods as needed\n",
    "\n",
    "if pruning_method.lower() not in supported_pruning_methods:\n",
    "    raise ValueError(f\"Pruning method '{pruning_method}' is not supported.\")\n",
    "\n",
    "\n",
    "for ratio in np.arange(0.0,1.0,0.1):    \n",
    "    statsMon = SystemStatsGatherer()\n",
    "    statsMon.startSampling()\n",
    "    ratio = round(ratio,2)\n",
    "    print(\"Pruning method:\", pruning_method)\n",
    "    print (ratio )\n",
    "    # Assuming you have a ResNet model defined\n",
    "\n",
    "\n",
    "\n",
    "    if pruning_method == 'l1_unstructured':\n",
    "        conv_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                if 'layer' in name:\n",
    "                    conv_layers_to_prune.append((module, name))\n",
    "        fc_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                fc_layers_to_prune.append((module, name))\n",
    "\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.l1_unstructured(layer, name='weight', amount=ratio)\n",
    "        for layer, name in fc_layers_to_prune:\n",
    "            prune.l1_unstructured(layer, name='weight', amount=ratio)\n",
    "\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.remove(layer, name='weight')\n",
    "\n",
    "    elif pruning_method == 'random_unstructured':\n",
    "        fc_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                fc_layers_to_prune.append((module, name))\n",
    "        conv_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "\n",
    "                if 'layer' in name:\n",
    "                    conv_layers_to_prune.append((module, name))\n",
    "\n",
    "\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.random_unstructured(layer, name='weight', amount=ratio)\n",
    "        for layer, name in fc_layers_to_prune:\n",
    "            prune.random_unstructured(layer, name='weight', amount=ratio)\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.remove(layer, name='weight')\n",
    "    elif pruning_method == 'random_structured':\n",
    "        fc_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                fc_layers_to_prune.append((module, name))\n",
    "        conv_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                if 'layer' in name:\n",
    "                    conv_layers_to_prune.append((module, name))\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.random_structured(layer, name='weight', amount=ratio)\n",
    "        for layer, name in fc_layers_to_prune:\n",
    "            prune.random_structured(layer, name='weight', amount=ratio)\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.remove(layer, name='weight')\n",
    "    elif pruning_method == 'ln_structured':\n",
    "        fc_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                fc_layers_to_prune.append((module, name))\n",
    "        conv_layers_to_prune = []\n",
    "        for name, module in model.named_modules():\n",
    "            if isinstance(module, torch.nn.Conv2d):\n",
    "                if 'layer' in name:\n",
    "                    conv_layers_to_prune.append((module, name))\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.ln_structured(layer, name='weight', amount=ratio,n=2)\n",
    "        for layer, name in fc_layers_to_prune:\n",
    "            prune.ln_structured(layer, name='weight', amount=ratio,n=2)\n",
    "        for layer, name in conv_layers_to_prune:\n",
    "            prune.remove(layer, name='weight')\n",
    "    \n",
    "\n",
    "\n",
    "    prof = torch.profiler.profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA, torch.profiler.ProfilerActivity],profile_memory=True, record_shapes=True,with_flops=True)\n",
    "    print ('Profiling run completed.\\nCompiling result table')\n",
    "    prof.start()\n",
    "    acc = __test__(model,model_name)\n",
    "    prof.stop()\n",
    "\n",
    "    print ('Profiling run completed.\\nCompiling result table')\n",
    "    prof_result = prof.key_averages().table(sort_by='cpu_memory_usage', row_limit=100)\n",
    "    prof_result_back = prof_result\n",
    "\n",
    "    #Trim off the header and footer of the results\n",
    "    prof_result_back = prof_result_back.rsplit(\"\\n\",3)[0]\n",
    "    prof_result__ = \"\"\n",
    "    for line in prof_result_back:\n",
    "        if \"-\" not in line.split():\n",
    "            prof_result__ += line \n",
    "    prof_result_back = prof_result__\n",
    "    # print (prof_result_back)\n",
    "    df = pd.read_csv(io.StringIO(prof_result_back), sep=\"\\s\\s+\")\n",
    "\n",
    "    # pd.set_option('display.max_rows', 500)\n",
    "    # display(df)\n",
    "\n",
    "    memory_consumption_str = df[(df['Name']=='[memory]')]['CPU Mem'].iloc[0]\n",
    "    \n",
    "\n",
    "    memory_consumption = 0\n",
    "    if ('Gb' in memory_consumption_str):\n",
    "        memory_consumption =  float(memory_consumption_str.split()[0])*1024*1024*1024\n",
    "    elif ('Mb' in memory_consumption_str):\n",
    "        memory_consumption =  float(memory_consumption_str.split()[0])*1024*1024\n",
    "    elif ('Kb' in memory_consumption_str):\n",
    "        memory_consumption =  float(memory_consumption_str.split()[0])*1024\n",
    "    elif ('b' in memory_consumption_str):\n",
    "        memory_consumption =  float(memory_consumption_str.split()[0])\n",
    "\n",
    "    print(ratio, memory_consumption, acc)\n",
    "    statsMon.stopSampling()\n",
    "    print('Collecting System Stats')\n",
    "    df_stats = pd.DataFrame.from_dict(statsMon.getReadings())\n",
    "    agg_df = df_stats[['vm_percent','swap_percent','cpuloadavg_1min', 'cpuloadavg_5min']]\n",
    "    agg_df__ =  agg_df.mean()\n",
    "    agg_df__['ratio'] = ratio\n",
    "    agg_df__['memory_consumption'] = memory_consumption\n",
    "    agg_df__['acc'] = acc\n",
    "    agg_df__['prune_config'] = f'{pruning_method}-ratio-{ratio}'\n",
    "    agg_df__['prune_ratio'] = ratio\n",
    "   \n",
    "    \n",
    "    display(agg_df__)\n",
    "    df_final = pd.concat([df_final,agg_df__], axis=1)\n",
    "    print('Aggregated stats')\n",
    "    display(df_final)\n",
    "    del prof_result\n",
    "del model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vm_percent</th>\n",
       "      <th>swap_percent</th>\n",
       "      <th>cpuloadavg_1min</th>\n",
       "      <th>cpuloadavg_5min</th>\n",
       "      <th>ratio</th>\n",
       "      <th>memory_consumption</th>\n",
       "      <th>acc</th>\n",
       "      <th>prune_config</th>\n",
       "      <th>prune_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.706135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35863.9</td>\n",
       "      <td>36641.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.346</td>\n",
       "      <td>l1_unstructured-ratio-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.968595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24983.675</td>\n",
       "      <td>25755.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.287999</td>\n",
       "      <td>l1_unstructured-ratio-0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.234328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29278.575</td>\n",
       "      <td>28741.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>80.214</td>\n",
       "      <td>l1_unstructured-ratio-0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66.967347</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12402.725</td>\n",
       "      <td>17852.325</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.0</td>\n",
       "      <td>79.597998</td>\n",
       "      <td>l1_unstructured-ratio-0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67.07234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4204.825</td>\n",
       "      <td>9529.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>77.089995</td>\n",
       "      <td>l1_unstructured-ratio-0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>68.015534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9296.925</td>\n",
       "      <td>8974.275</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70.694</td>\n",
       "      <td>l1_unstructured-ratio-0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>68.407692</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11986.975</td>\n",
       "      <td>10632.975</td>\n",
       "      <td>0.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>44.25</td>\n",
       "      <td>l1_unstructured-ratio-0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>68.678095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12636.425</td>\n",
       "      <td>11827.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.928</td>\n",
       "      <td>l1_unstructured-ratio-0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>70.363441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8442.65</td>\n",
       "      <td>10112.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1_unstructured-ratio-0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72.204255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4559.25</td>\n",
       "      <td>6927.425</td>\n",
       "      <td>0.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l1_unstructured-ratio-0.9</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  vm_percent swap_percent cpuloadavg_1min cpuloadavg_5min ratio  \\\n",
       "0  67.706135          0.0         35863.9         36641.2   0.0   \n",
       "1  65.968595          0.0       24983.675         25755.1   0.1   \n",
       "2  67.234328          0.0       29278.575        28741.25   0.2   \n",
       "3  66.967347          0.0       12402.725       17852.325   0.3   \n",
       "4   67.07234          0.0        4204.825          9529.9   0.4   \n",
       "5  68.015534          0.0        9296.925        8974.275   0.5   \n",
       "6  68.407692          0.0       11986.975       10632.975   0.6   \n",
       "7  68.678095          0.0       12636.425         11827.3   0.7   \n",
       "8  70.363441          0.0         8442.65         10112.9   0.8   \n",
       "9  72.204255          0.0         4559.25        6927.425   0.9   \n",
       "\n",
       "  memory_consumption        acc               prune_config prune_ratio  \n",
       "0               12.0     80.346  l1_unstructured-ratio-0.0         0.0  \n",
       "1               12.0  80.287999  l1_unstructured-ratio-0.1         0.1  \n",
       "2               12.0     80.214  l1_unstructured-ratio-0.2         0.2  \n",
       "3               12.0  79.597998  l1_unstructured-ratio-0.3         0.3  \n",
       "4               12.0  77.089995  l1_unstructured-ratio-0.4         0.4  \n",
       "5               12.0     70.694  l1_unstructured-ratio-0.5         0.5  \n",
       "6               12.0      44.25  l1_unstructured-ratio-0.6         0.6  \n",
       "7               12.0      1.928  l1_unstructured-ratio-0.7         0.7  \n",
       "8               12.0        0.1  l1_unstructured-ratio-0.8         0.8  \n",
       "9               12.0        0.1  l1_unstructured-ratio-0.9         0.9  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the directory where the CSV files will be saved\n",
    "SAVE_DIR = BASE_DIR\n",
    "\n",
    "# Define a function to generate the filename based on model name and pruning method\n",
    "def generate_filename(model_name, pruning_method):\n",
    "    # Replace spaces with underscores and concatenate with '.csv' extension\n",
    "    filename = f\"{model_name.replace(' ', '_')}_{pruning_method}.csv\"\n",
    "    # Combine with the directory path\n",
    "    return SAVE_DIR + filename\n",
    "\n",
    "# Use the function to generate the filename\n",
    "DF_SAVEFILENAME = generate_filename(model_name, pruning_method)\n",
    "\n",
    "# Save the DataFrame to CSV\n",
    "df_final_transpose = df_final.transpose().reset_index(drop=True)\n",
    "display(df_final_transpose)\n",
    "df_final_transpose.to_csv(DF_SAVEFILENAME, encoding='utf-8', sep=',')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
